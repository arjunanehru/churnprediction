{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Azure ML libraries\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Model\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.resource_configuration import ResourceConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using version 1.0.83 of the Azure ML SDK.\n",
      "\n",
      "Workspace name: sbirkamlws\n",
      "Azure region: northcentralus\n",
      "Subscription id: bf088f59-f015-4332-bd36-54b988be7c90\n",
      "Resource group: sbirkamlrg\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK.\")\n",
    "print(\"\")\n",
    "\n",
    "# Load workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Files for Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_training/customer_churn.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a folder for the experiment files\n",
    "training_folder = 'model_training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/customer_churn.csv', os.path.join(training_folder, \"customer_churn.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training script in the experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/customer_churn_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/customer_churn_training.py\n",
    "\n",
    "### Setup\n",
    "## Import libraries\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import argparse\n",
    "\n",
    "# Azure ML libraries\n",
    "from azureml.core import Run\n",
    "\n",
    "# Data preprocessing libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model training libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import scorer, f1_score, precision_score, recall_score, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Visualization libraries\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as sp\n",
    "import plotly.offline as py\n",
    "import plotly.io as pio\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# configure plotly.py to run orca using Xvfb\n",
    "pio.orca.config.use_xvfb = True\n",
    "pio.orca.config.save()\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading Data...\")\n",
    "telcom = pd.read_csv('customer_churn.csv')\n",
    "\n",
    "\n",
    "### Data preprocessing\n",
    "# Replace spaces with null values in total charges column\n",
    "telcom['TotalCharges'] = telcom[\"TotalCharges\"].replace(\" \",np.nan)\n",
    "\n",
    "# Drop null values from total charges column which contains .15% missing data \n",
    "telcom = telcom[telcom[\"TotalCharges\"].notnull()]\n",
    "telcom = telcom.reset_index()[telcom.columns]\n",
    "\n",
    "# Convert total charges to float type\n",
    "telcom[\"TotalCharges\"] = telcom[\"TotalCharges\"].astype(float)\n",
    "\n",
    "# Replace 'No internet service' to No for the following columns\n",
    "replace_cols = [\"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "                \"TechSupport\",\"StreamingTV\", \"StreamingMovies\"]\n",
    "for i in replace_cols : \n",
    "    telcom[i]  = telcom[i].replace({\"No internet service\" : \"No\"})\n",
    "    \n",
    "# Replace values for Senior Citizen column\n",
    "telcom[\"SeniorCitizen\"] = telcom[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n",
    "\n",
    "# Transform Tenure to categorical column\n",
    "def tenure_lab(telcom) :    \n",
    "    if telcom[\"tenure\"] <= 12 :\n",
    "        return \"Tenure_0-12\"\n",
    "    elif (telcom[\"tenure\"] > 12) & (telcom[\"tenure\"] <= 24 ):\n",
    "        return \"Tenure_12-24\"\n",
    "    elif (telcom[\"tenure\"] > 24) & (telcom[\"tenure\"] <= 48) :\n",
    "        return \"Tenure_24-48\"\n",
    "    elif (telcom[\"tenure\"] > 48) & (telcom[\"tenure\"] <= 60) :\n",
    "        return \"Tenure_48-60\"\n",
    "    elif telcom[\"tenure\"] > 60 :\n",
    "        return \"Tenure_gt_60\"\n",
    "    \n",
    "telcom[\"tenure_group\"] = telcom.apply(lambda telcom:tenure_lab(telcom), axis = 1)\n",
    "\n",
    "# ID column\n",
    "Id_col     = ['customerID']\n",
    "\n",
    "# Target column\n",
    "target_col = [\"Churn\"]\n",
    "\n",
    "# Categorical feature columns\n",
    "cat_cols   = telcom.nunique()[telcom.nunique() < 6].keys().tolist() # get columns with less than 6 unique values\n",
    "cat_cols   = [x for x in cat_cols if x not in target_col] # exclude target column (which is also categorical)\n",
    "\n",
    "# Numerical feature columns\n",
    "num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col + Id_col]\n",
    "\n",
    "# Binary columns with two values\n",
    "bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "\n",
    "# Columns with more than two values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "# Label encoding of binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    telcom[i] = le.fit_transform(telcom[i])\n",
    "    \n",
    "# Build dummy columns for multi value columns\n",
    "telcom = pd.get_dummies(data = telcom,columns = multi_cols)\n",
    "\n",
    "# Scaling of numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(telcom[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "# Dropping original values and merging scaled values for numerical columns\n",
    "telcom = telcom.drop(columns = num_cols,axis = 1)\n",
    "telcom = telcom.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "\n",
    "\n",
    "### Model Training\n",
    "# Split data into train and test\n",
    "train,test = train_test_split(telcom, test_size = .25 ,random_state = 42)\n",
    "    \n",
    "# Separate dependent and independent variables and exclude ID column\n",
    "cols    = [i for i in telcom.columns if i not in Id_col + target_col]\n",
    "train_X = train[cols]\n",
    "train_Y = train[target_col]\n",
    "test_X  = test[cols]\n",
    "test_Y  = test[target_col]\n",
    "\n",
    "# Write a function for generic model training    \n",
    "def telecom_churn_prediction(algorithm,training_x,testing_x,\n",
    "                             training_y,testing_y,cols,cf):\n",
    "    '''\n",
    "    Function signature\n",
    "    algorithm     - algorithm used \n",
    "    training_x    - predictor variables dataframe (training)\n",
    "    testing_x     - predictor variables dataframe (testing)\n",
    "    training_y    - target variable (training)\n",
    "    training_y    - target variable (testing)\n",
    "    cols          - features\n",
    "    cf - [\"coefficients\",\"features\"] (cooefficients for logistic regression, features for tree based models)\n",
    "    '''\n",
    "    \n",
    "    # Fit the model\n",
    "    algorithm.fit(training_x,training_y)\n",
    "    predictions   = algorithm.predict(testing_x)\n",
    "    probabilities = algorithm.predict_proba(testing_x)\n",
    "    \n",
    "    # Store coefficients\n",
    "    if   cf == \"coefficients\" :\n",
    "        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n",
    "    elif cf == \"features\" :\n",
    "        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n",
    "        \n",
    "    column_df     = pd.DataFrame(cols)\n",
    "    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    class_report = classification_report(testing_y,predictions)\n",
    "    class_metrics = precision_recall_fscore_support(testing_y, predictions, beta=1.0, average=\"binary\", pos_label=0)\n",
    "    accuracy = accuracy_score(testing_y,predictions)\n",
    "    conf_matrix = confusion_matrix(testing_y,predictions)\n",
    "    model_roc_auc = roc_auc_score(testing_y,predictions)\n",
    "    \n",
    "    precision = class_metrics[0]\n",
    "    recall = class_metrics[1]\n",
    "    fscore = class_metrics[2]\n",
    "    \n",
    "    # Log and print model evaluation information\n",
    "    print (algorithm)\n",
    "    \n",
    "    print (\"\\n Classification report : \\n\", class_report)\n",
    "    \n",
    "    print (\"Accuracy Score : \", accuracy)\n",
    "    run.log(\"Accuracy\", np.float(accuracy))    \n",
    "    \n",
    "    print (\"Area Under Curve : \",model_roc_auc,\"\\n\")\n",
    "    run.log(\"AUC\", np.float(model_roc_auc))\n",
    "    \n",
    "    print (\"Precision : \",precision,\"\\n\")\n",
    "    run.log(\"Precision\", np.float(precision))\n",
    "    \n",
    "    print (\"Recall : \",recall,\"\\n\")\n",
    "    run.log(\"Recall\", np.float(recall))\n",
    "    \n",
    "    print (\"F Score : \",fscore,\"\\n\")\n",
    "    run.log(\"F Score\", np.float(fscore))\n",
    "    \n",
    "    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    class_names = [\"Churn\", \"Non Churn\"]\n",
    "    \n",
    "    trace1 = plot_confusion_matrix(algorithm, testing_x, testing_y,\n",
    "                                   display_labels=class_names,\n",
    "                                   cmap=\"inferno\",\n",
    "                                   normalize=\"true\")\n",
    "    \n",
    "    trace1.ax_.set_title(\"Normalized Confusion Matrix\")\n",
    "    trace1.ax_.grid(False)\n",
    "    run.log_image(\"Normalized Confusion Matrix\", plot=plt)\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot roc curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % model_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    run.log_image(\"Receiver Operating Characteristic\", plot=plt)\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot feature importance\n",
    "    x = coef_sumry[\"features\"]\n",
    "    y = coef_sumry[\"coefficients\"]\n",
    "\n",
    "    mask1 = y >= 0\n",
    "    mask2 = y < 0\n",
    "\n",
    "    objects = coef_sumry[\"features\"]\n",
    "    x_pos = np.arange(len(coef_sumry[\"features\"]))\n",
    "\n",
    "    plt.bar(x[mask1], y[mask1], color = 'green')\n",
    "    plt.bar(x[mask2], y[mask2], color = 'red')\n",
    "    plt.xticks(x_pos, x, rotation='vertical')\n",
    "    plt.yticks(rotation='horizontal')\n",
    "    plt.ylabel('Feature Coefficient')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    run.log_image(\"Feature Importance\", plot=plt)\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    '''\n",
    "    # Plot confusion matrix\n",
    "    trace1 = go.Heatmap(z = conf_matrix ,\n",
    "                        x = [\"Not churn\",\"Churn\"],\n",
    "                        y = [\"Not churn\",\"Churn\"],\n",
    "                        showscale  = False,colorscale = \"Picnic\",\n",
    "                        name = \"matrix\")\n",
    "    \n",
    "    # Plot roc curve\n",
    "    trace2 = go.Scatter(x = fpr,y = tpr,\n",
    "                        name = \"Roc : \" + str(model_roc_auc),\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n",
    "    trace3 = go.Scatter(x = [0,1],y=[0,1],\n",
    "                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    # Plot coefficients\n",
    "    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_sumry[\"coefficients\"],\n",
    "                                  colorscale = \"Picnic\",\n",
    "                                  line = dict(width = .6,color = \"black\")))\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = sp.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                            subplot_titles=('Confusion Matrix',\n",
    "                                            'Receiver operating characteristic',\n",
    "                                            'Feature Importances'))\n",
    "    \n",
    "    fig.append_trace(trace1,1,1)\n",
    "    fig.append_trace(trace2,1,2)\n",
    "    fig.append_trace(trace3,1,2)\n",
    "    fig.append_trace(trace4,2,1)\n",
    "    \n",
    "    # Plot layout\n",
    "    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n",
    "                         autosize = False,height = 900,width = 800,\n",
    "                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         margin = dict(b = 195))\n",
    "    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n",
    "                                        tickangle = 90))\n",
    "    \n",
    "    image_path = \"outputs/log_reg_graphs.png\"\n",
    "    fig.write_image(image_path)\n",
    "    # upload the file explicitly into artifacts \n",
    "    run.upload_file(name = image_path, path_or_stream = image_path)\n",
    "    '''\n",
    "    \n",
    "    return algorithm\n",
    "        \n",
    "# Build logistic regression model\n",
    "\n",
    "# Expose regularization hyperparameter as script argument\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "run.log('Regularization Hyperparameter Lambda', np.float(reg)) # this is retrieved as script argument\n",
    "\n",
    "logit = LogisticRegression(C=1/reg, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "logit_fitted = telecom_churn_prediction(logit,train_X,test_X,train_Y,test_Y,\n",
    "                         cols,\"coefficients\")\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "joblib.dump(value=logit_fitted, filename='outputs/customer_churn_log_reg_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use an Estimator to Run the Script as an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: customer-churn-log-reg-experiment_1580814694_86381982\n",
      "Web View: https://ml.azure.com/experiments/customer-churn-log-reg-experiment/runs/customer-churn-log-reg-experiment_1580814694_86381982?wsid=/subscriptions/bf088f59-f015-4332-bd36-54b988be7c90/resourcegroups/sbirkamlrg/workspaces/sbirkamlws\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 10\n",
      "Entering Run History Context Manager.\n",
      "/azureml-envs/azureml_b801e5ddb9f8efe313713a85e8a72474/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Loading Data...\n",
      "/azureml-envs/azureml_b801e5ddb9f8efe313713a85e8a72474/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      " Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1300\n",
      "           1       0.62      0.47      0.54       458\n",
      "\n",
      "    accuracy                           0.79      1758\n",
      "   macro avg       0.73      0.69      0.70      1758\n",
      "weighted avg       0.78      0.79      0.78      1758\n",
      "\n",
      "Accuracy Score :  0.78839590443686\n",
      "Area Under Curve :  0.6865149479341619 \n",
      "\n",
      "Precision :  0.8290780141843972 \n",
      "\n",
      "Recall :  0.8992307692307693 \n",
      "\n",
      "F Score :  0.862730627306273 \n",
      "\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 10\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.0008296966552734375 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: customer-churn-log-reg-experiment_1580814694_86381982\n",
      "Web View: https://ml.azure.com/experiments/customer-churn-log-reg-experiment/runs/customer-churn-log-reg-experiment_1580814694_86381982?wsid=/subscriptions/bf088f59-f015-4332-bd36-54b988be7c90/resourcegroups/sbirkamlrg/workspaces/sbirkamlws\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'customer-churn-log-reg-experiment_1580814694_86381982',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-02-04T11:11:37.054446Z',\n",
       " 'endTimeUtc': '2020-02-04T11:11:47.248712Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '7284c6c9-990f-405d-ad22-a1490fa705eb'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'customer_churn_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--reg_rate', '0.01'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment customer-churn-log-reg-experiment Environment',\n",
       "   'version': 'Autosave_2020-02-04T11:06:30Z_8ccdb337',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults', 'matplotlib']},\n",
       "      'scikit-learn',\n",
       "      'statsmodels',\n",
       "      'plotly',\n",
       "      'psutil'],\n",
       "     'name': 'azureml_b801e5ddb9f8efe313713a85e8a72474'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://sbirkamlws5448716397.blob.core.windows.net/azureml/ExperimentRun/dcid.customer-churn-log-reg-experiment_1580814694_86381982/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=3LNZ4DiGnLypZzMBHvEpfVnHR%2FSXAtV8I1Fsk4uuZCU%3D&st=2020-02-04T11%3A01%3A48Z&se=2020-02-04T19%3A11%3A48Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://sbirkamlws5448716397.blob.core.windows.net/azureml/ExperimentRun/dcid.customer-churn-log-reg-experiment_1580814694_86381982/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=B9Ar7%2B6O0dYmtQE0o3Dh7HXOC8oRh1Y5mkzBb4PwAAc%3D&st=2020-02-04T11%3A01%3A48Z&se=2020-02-04T19%3A11%3A48Z&sp=r',\n",
       "  'logs/azureml/10_azureml.log': 'https://sbirkamlws5448716397.blob.core.windows.net/azureml/ExperimentRun/dcid.customer-churn-log-reg-experiment_1580814694_86381982/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=iaiF5kQQ1Pj6Hm58d3z9WKmydpJ9Izrd2%2BscDgYtE04%3D&st=2020-02-04T11%3A01%3A48Z&se=2020-02-04T19%3A11%3A48Z&sp=r'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                      entry_script='customer_churn_training.py',\n",
    "                      script_params = {'--reg_rate': 0.01},\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn', 'statsmodels', 'plotly', 'psutil'],\n",
    "                      pip_packages=['matplotlib']\n",
    "                      )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'customer-churn-log-reg-experiment'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "run = experiment.submit(config=estimator)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d03208aea149b1b97b5adf726aaa85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/customer-churn-log-reg-experiment/runs/customer-churn-log-reg-experiment_1580814694_86381982?wsid=/subscriptions/bf088f59-f015-4332-bd36-54b988be7c90/resourcegroups/sbirkamlrg/workspaces/sbirkamlws\", \"run_id\": \"customer-churn-log-reg-experiment_1580814694_86381982\", \"run_properties\": {\"run_id\": \"customer-churn-log-reg-experiment_1580814694_86381982\", \"created_utc\": \"2020-02-04T11:11:35.507599Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"7284c6c9-990f-405d-ad22-a1490fa705eb\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-02-04T11:11:47.248712Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://sbirkamlws5448716397.blob.core.windows.net/azureml/ExperimentRun/dcid.customer-churn-log-reg-experiment_1580814694_86381982/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=ir1I2bZE1wx7dXMmWcGpDn7AfQfSTyrXPDLxoij7lsk%3D&st=2020-02-04T11%3A01%3A49Z&se=2020-02-04T19%3A11%3A49Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://sbirkamlws5448716397.blob.core.windows.net/azureml/ExperimentRun/dcid.customer-churn-log-reg-experiment_1580814694_86381982/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=J8gpM5VZ%2Bgk7A6KXJLbz4satNp1Qj8vDnmEUKc0Mu%2BI%3D&st=2020-02-04T11%3A01%3A49Z&se=2020-02-04T19%3A11%3A49Z&sp=r\", \"logs/azureml/10_azureml.log\": \"https://sbirkamlws5448716397.blob.core.windows.net/azureml/ExperimentRun/dcid.customer-churn-log-reg-experiment_1580814694_86381982/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=nUXGgisuPzCB4vIuIU5%2FRWDkIh6RhX9%2F9C3G2WJzUiU%3D&st=2020-02-04T11%3A01%3A49Z&se=2020-02-04T19%3A11%3A49Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/10_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:11\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Starting the daemon thread to refresh tokens in background for process with pid = 10\\nEntering Run History Context Manager.\\n/azureml-envs/azureml_b801e5ddb9f8efe313713a85e8a72474/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\\n  warnings.warn(message, FutureWarning)\\nLoading Data...\\n/azureml-envs/azureml_b801e5ddb9f8efe313713a85e8a72474/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning:\\n\\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\\n\\nLogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\\n                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\\n\\n Classification report : \\n               precision    recall  f1-score   support\\n\\n           0       0.83      0.90      0.86      1300\\n           1       0.62      0.47      0.54       458\\n\\n    accuracy                           0.79      1758\\n   macro avg       0.73      0.69      0.70      1758\\nweighted avg       0.78      0.79      0.78      1758\\n\\nAccuracy Score :  0.78839590443686\\nArea Under Curve :  0.6865149479341619 \\n\\nPrecision :  0.8290780141843972 \\n\\nRecall :  0.8992307692307693 \\n\\nF Score :  0.862730627306273 \\n\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.0008296966552734375 seconds\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_churn_log_reg_model version: 3\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6865149479341619\n",
      "\t Accuracy : 0.78839590443686\n",
      "\t Precision : 0.8290780141843972\n",
      "\t Recall : 0.8992307692307693\n",
      "\t F Score : 0.862730627306273\n",
      "\n",
      "\n",
      "customer_churn_dt_model version: 2\n",
      "\t Training Context : Notebook\n",
      "\t Algorithm : Decision Tree\n",
      "\n",
      "\n",
      "customer_churn_log_reg_model version: 2\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6865149479341619\n",
      "\t Accuracy : 0.78839590443686\n",
      "\t Precision : 0.8290780141843972\n",
      "\t Recall : 0.8992307692307693\n",
      "\t F Score : 0.862730627306273\n",
      "\n",
      "\n",
      "AutoMLd0a94946323 version: 1\n",
      "\n",
      "\n",
      "customer_churn_log_reg_model version: 1\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6894675848169298\n",
      "\t Accuracy : 0.7906712172923777\n",
      "\t Precision : 0.8304964539007093\n",
      "\t Recall : 0.9007692307692308\n",
      "\t F Score : 0.8642066420664208\n",
      "\n",
      "\n",
      "customer_churn_dt_model version: 1\n",
      "\t Training Context : Notebook\n",
      "\t Algorithm : Decision Tree\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the model\n",
    "run.register_model(model_path='outputs/customer_churn_log_reg_model.pkl', model_name='customer_churn_log_reg_model',\n",
    "                   tags={'Training Context':'Estimator', 'Algorithm':'Logistic Regression'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy'],\n",
    "                              'Precision': run.get_metrics()['Precision'], 'Recall': run.get_metrics()['Recall'],\n",
    "                              'F Score': run.get_metrics()['F Score']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
