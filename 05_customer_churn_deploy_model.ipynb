{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will deploy the logistic regression model (that we have trained in notebook\n",
    "**\"02_customer_churn_train_logistic_regression.ipynb\"**) as a real time service that can be called via Azure ML SDK or Rest request to make a prediction on a new data point.\n",
    "\n",
    "To this end, we will deploy the model as a web service hosted in a container.\n",
    "\n",
    "In general, in Azure ML you can deploy a model either with Azure Container Instances (ACI) or Azure Kubernetes Service (AKS). \n",
    "\n",
    "ACI is only suited for development and testing purposes.\n",
    "\n",
    "We will deploy our model on an Azure Kubernetes Service (AKS) cluster and will enable required authentication. This will require REST requests to include an authorization header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll deploy the model as a service named **churn-prediction-service-1**.\n",
    "The deployment process includes the following steps:\n",
    "\n",
    "1. Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n",
    "2. Define a deployment configuration that defines the execution environment in which the service will be hosted.\n",
    "   In this case, an Azure Kubernetes Cluster.\n",
    "3. Deploy the model as a web service.\n",
    "4. Verify the status of the deployed service.\n",
    "\n",
    "Deployment will take some time as it first runs a process to create a container image, and then runs a process \n",
    "to create a web service based on the image. When deployment has completed successfully, you'll see a status of Healthy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "# Standard libraries\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Azure ML SDK libraries\n",
    "from azureml.core import Model, Workspace, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML SDK 1.0.85 to work with wschurnazuremldemo\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from the config file. If this notebook runs in Azure ML, from_config() will do the job.\n",
    "ws = Workspace.from_config()\n",
    "print(\"Ready to use Azure ML SDK {} to work with {}\".format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Models from Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_churn_dt_model version: 1\n",
      "\t Training Context : Notebook\n",
      "\t Algorithm : Decision Tree\n",
      "\n",
      "\n",
      "customer_churn_log_reg_model version: 1\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.7065752294266209\n",
      "\t Accuracy : 0.7998580553584103\n",
      "\t Precision : 0.8240495137046862\n",
      "\t Recall : 0.9182266009852217\n",
      "\t F Score : 0.8685927306616963\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in Model.list(ws):\n",
    "    print(model.name, \"version:\", model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print (\"\\t\",tag_name, \":\", tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print (\"\\t\",prop_name, \":\", prop)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_churn_log_reg_model version 1\n"
     ]
    }
   ],
   "source": [
    "# We will deploy our logistic regression model here\n",
    "model = ws.models[\"customer_churn_log_reg_model\"] # by default latest version\n",
    "print(model.name, \"version\", model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Folder and Score File to Host Web Service for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_service folder created.\n"
     ]
    }
   ],
   "source": [
    "service_folder = \"model_service\"\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + service_folder\n",
    "os.makedirs(service_folder, exist_ok=True)\n",
    "\n",
    "print(service_folder, \"folder created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_service/utilities/preprocess_dataset.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create folder \"utilities\"\n",
    "os.makedirs(\"utilities\", exist_ok=True)\n",
    "\n",
    "# Copy the utility files into the experiment folder\n",
    "os.makedirs(service_folder + \"/utilities\", exist_ok=True)\n",
    "shutil.copy(\"utilities/preprocess_dataset.py\", os.path.join(service_folder, \"utilities/preprocess_dataset.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_service/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $service_folder/score.py\n",
    "\n",
    "# Import preprocessing function which is defined in utilities folder\n",
    "import utilities.preprocess_dataset\n",
    "\n",
    "# Install libraries\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'customer_churn_log_reg_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    # Preprocess the data\n",
    "    data_processed = utilities.preprocess_dataset.run(data, training_mode=False)\n",
    "    # Get the prediction and the corresponding probabilities from the model\n",
    "    predictions = model.predict(data_processed)\n",
    "    prediction_probas = model.predict_proba(data_processed)\n",
    "    # Get the corresponding classnames for each prediction (0 or 1)\n",
    "    classnames = [\"Non Churn\", \"Churn\"]\n",
    "    predicted_classes = []\n",
    "    predicted_classes_probas = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    for prediction_proba in prediction_probas:\n",
    "        predicted_classes_probas.append(list(prediction_proba))\n",
    "    # Return the predictions and their corresponding probabilities as JSON\n",
    "    return json.dumps({\"predicted_classes\":predicted_classes, \"predicted_classes_probas\":predicted_classes_probas})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dependencies and Inference Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dependencies and build a new environment with these dependencies\n",
    "conda_deps = CondaDependencies.create(conda_packages=['numpy','scikit-learn==0.22.1'],\n",
    "                                      pip_packages=['azureml-defaults','azureml-core'])\n",
    "myenv = Environment(name='myenv')\n",
    "myenv.python.conda_dependencies = conda_deps\n",
    "\n",
    "# use an image available in public Container Registry without authentication\n",
    "# myenv.docker.base_image = \"mcr.microsoft.com/azureml/o16n-sample-user-base/ubuntu-'miniconda\"\n",
    "# myenv.inferencing_stack_version='latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference config\n",
    "inf_config = InferenceConfig(source_directory=service_folder, \n",
    "                             entry_script='score.py',\n",
    "                             environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision Azure Kubernetes Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "aks_name = 'aks-1' \n",
    "\n",
    "# Create the cluster if not already created\n",
    "try:\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "except:\n",
    "    aks_target = ComputeTarget(workspace = ws, name = aks_name)\n",
    "\n",
    "# Wait for aks cluster\n",
    "aks_target.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure AKS Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "# Set the web service configuration (using default here)\n",
    "# aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "# Option 2:\n",
    "# Enable token authentication and disable (key) authentication on the webservice\n",
    "aks_config = AksWebservice.deploy_configuration(token_auth_enabled=True, auth_enabled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service_name = \"churn-prediction-service-1\"\n",
    "\n",
    "aks_service = Model.deploy(workspace=ws,\n",
    "                           name=aks_service_name,\n",
    "                           models=[model],\n",
    "                           inference_config=inf_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "\n",
    "# Get service state\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get service logs\n",
    "# print(aks_service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to make a change and redeploy, you may need to delete the unhealthy service using the following code:\n",
    "# aks_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Web Services from Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn==0.22.1\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/customer_churn_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
