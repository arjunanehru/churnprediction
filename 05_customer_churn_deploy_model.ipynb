{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a real time service that can be called via Azure ML SDK or REST request to make a prediction on new data.\n",
    "To this end, deploy the model as a web service hosted in a container.\n",
    "\n",
    "The model will be deployed as an Azure Container Instance (ACI) service that requires no authentication. This is fine for development and testing, but for production you should consider deploying to an Azure Kubernetes Service (AKS) cluster and enabling authentication. This would require REST requests to include an Authorization header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "\n",
    "# Azure ML libraries\n",
    "import azureml.core\n",
    "from azureml.core import Model, Workspace\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.0.83 to work with sbirkamlws\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print(\"Ready to use Azure ML {} to work with {}\".format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Models from Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_churn_log_reg_model version: 4\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6876066509909305\n",
      "\t Accuracy : 0.7889647326507395\n",
      "\t Precision : 0.829666430092264\n",
      "\t Recall : 0.8992307692307693\n",
      "\t F Score : 0.8630490956072352\n",
      "\n",
      "\n",
      "customer_churn_dt_model version: 3\n",
      "\t Training Context : Notebook\n",
      "\t Algorithm : Decision Tree\n",
      "\n",
      "\n",
      "customer_churn_log_reg_model version: 3\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6865149479341619\n",
      "\t Accuracy : 0.78839590443686\n",
      "\t Precision : 0.8290780141843972\n",
      "\t Recall : 0.8992307692307693\n",
      "\t F Score : 0.862730627306273\n",
      "\n",
      "\n",
      "customer_churn_dt_model version: 2\n",
      "\t Training Context : Notebook\n",
      "\t Algorithm : Decision Tree\n",
      "\n",
      "\n",
      "customer_churn_log_reg_model version: 2\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6865149479341619\n",
      "\t Accuracy : 0.78839590443686\n",
      "\t Precision : 0.8290780141843972\n",
      "\t Recall : 0.8992307692307693\n",
      "\t F Score : 0.862730627306273\n",
      "\n",
      "\n",
      "AutoMLd0a94946323 version: 1\n",
      "\n",
      "\n",
      "customer_churn_log_reg_model version: 1\n",
      "\t Training Context : Estimator\n",
      "\t Algorithm : Logistic Regression\n",
      "\t AUC : 0.6894675848169298\n",
      "\t Accuracy : 0.7906712172923777\n",
      "\t Precision : 0.8304964539007093\n",
      "\t Recall : 0.9007692307692308\n",
      "\t F Score : 0.8642066420664208\n",
      "\n",
      "\n",
      "customer_churn_dt_model version: 1\n",
      "\t Training Context : Notebook\n",
      "\t Algorithm : Decision Tree\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in Model.list(ws):\n",
    "    print(model.name, \"version:\", model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print (\"\\t\",tag_name, \":\", tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print (\"\\t\",prop_name, \":\", prop)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return a Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_churn_log_reg_model version 4\n"
     ]
    }
   ],
   "source": [
    "model = ws.models[\"customer_churn_log_reg_model\"] # by default latest version\n",
    "print(model.name, \"version\", model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Folder and Score File to Host Web Service for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_churn_service folder created.\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"customer_churn_service\"\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, \"folder created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting customer_churn_service/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/score.py\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'customer_churn_log_reg_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = [\"Non Churn\", \"Churn\"]\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dependencies and Inference Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "conda_deps = CondaDependencies.create(conda_packages=['numpy','scikit-learn==0.22.1'],\n",
    "                                      pip_packages=['azureml-defaults','azureml-core'])\n",
    "myenv = Environment(name='myenv')\n",
    "myenv.python.conda_dependencies = conda_deps\n",
    "\n",
    "# use an image available in public Container Registry without authentication\n",
    "# myenv.docker.base_image = \"mcr.microsoft.com/azureml/o16n-sample-user-base/ubuntu-miniconda\"\n",
    "# myenv.inferencing_stack_version='latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inf_config = InferenceConfig(entry_script=os.path.join(folder_name,'score.py'), environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision Azure Kubernetes Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "aks_name = 'sbirkamlaks' \n",
    "\n",
    "# Create the cluster if not already created\n",
    "try:\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "except:\n",
    "    aks_target = ComputeTarget(workspace = ws, name = aks_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the web service configuration (using default here)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "# # Enable token auth and disable (key) auth on the webservice\n",
    "# aks_config = AksWebservice.deploy_configuration(token_auth_enabled=True, auth_enabled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "aks_service_name = \"aks-service-3\"\n",
    "\n",
    "aks_service = Model.deploy(workspace=ws,\n",
    "                           name=aks_service_name,\n",
    "                           models=[model],\n",
    "                           inference_config=inf_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn==0.22.1\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/customer_churn_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you're ready to deploy. We'll deploy the container a service named customer-churn-service.\n",
    "# The deployment process includes the following steps:\n",
    "\n",
    "# 1. Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n",
    "# 2. Define a deployment configuration that defines the execution environment in which the service will be hosted.\n",
    "#    In this case, an Azure Container Instance.\n",
    "# 3. Deploy the model as a web service.\n",
    "# 4. Verify the status of the deployed service.\n",
    "\n",
    "# Deployment will take some time as it first runs a process to create a container image, and then runs a process \n",
    "# to create a web service based on the image. When deployment has completed successfully, you'll see a status of Healthy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Web Service in ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"score_customer_churn.py\",\n",
    "                                   conda_file=\"customer_churn_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Deploy model\n",
    "service_name = \"customer-churn-service-sdk\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(service.state)\n",
    "print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Web Services from Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aks-service-3\n",
      "aks-service-1\n",
      "aks-service-2\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
